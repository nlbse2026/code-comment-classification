{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c546aa23-dc4f-4882-911d-b751a64fe5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pip install setfit==1.1.2 datasets=3.6.0\n",
    "# expects that the folder models exists\n",
    "import pandas as pd\n",
    "import time\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba5ab32-a3d9-468a-a70c-7010123f2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['java', 'python', 'pharo']\n",
    "labels = {\n",
    "    'java': ['summary', 'Ownership', 'Expand', 'usage', 'Pointer', 'deprecation', 'rational'],\n",
    "    'python': ['Usage', 'Parameters', 'DevelopmentNotes', 'Expand', 'Summary'],\n",
    "    'pharo': ['Keyimplementationpoints', 'Example', 'Responsibilities', 'Intent', 'Keymessages', 'Collaborators']\n",
    "}\n",
    "ds = load_dataset('NLBSE/nlbse26-code-comment-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39abcb0-235a-4e6d-9f89-d585711c7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs:\n",
    "    model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\", multi_target_strategy=\"multi-output\")\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        num_epochs=5 if lang == 'java' else 10,\n",
    "        batch_size=32,\n",
    "        num_iterations=20\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=ds[f'{lang}_train'],\n",
    "        eval_dataset=ds[f'{lang}_test'],\n",
    "        column_mapping={\"combo\": \"text\", \"labels\": \"label\"}\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.model.save_pretrained(f'./models/{lang}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5049af86-918a-4f50-8a2c-4ad922f3f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute in GFLOPs: 0.355315968\n",
      "Avg runtime in seconds: 0.9584410905838012\n"
     ]
    }
   ],
   "source": [
    "total_flops = 0\n",
    "total_time = 0\n",
    "scores = []\n",
    "for lan in langs:\n",
    "    # to load trained models:\n",
    "    # model = SetFitModel.from_pretrained(f'./models/{lan}')\n",
    "    # to load pretrained models from Hub:\n",
    "    model = SetFitModel.from_pretrained(f'NLBSE/nlbse26_{lan}')\n",
    "    with torch.profiler.profile(with_flops=True) as p:\n",
    "        x = ds[f'{lan}_test'][:][\"combo\"]\n",
    "        begin = time.time()\n",
    "        for i in range(10):\n",
    "          y_pred = model(x)\n",
    "          y_pred = np.asarray(y_pred).T \n",
    "        total = time.time() - begin\n",
    "        total_time = total_time + total\n",
    "    total_flops = total_flops + (sum(k.flops for k in p.key_averages()) / 1e9)\n",
    "    y_true = np.array(ds[f'{lan}_test']['labels']).T\n",
    "    for i in range(len(y_pred)):\n",
    "        assert(len(y_pred[i]) == len(y_true[i]))\n",
    "        tp = sum([true == pred == 1 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        tn = sum([true == pred == 0 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        fp = sum([true == 0 and pred == 1 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        fn = sum([true == 1 and pred == 0 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*tp) / (2*tp + fp + fn)\n",
    "        scores.append({'lan': lan, 'cat': labels[lan][i],'precision': precision,'recall': recall,'f1': f1})\n",
    "print(\"Compute in GFLOPs:\", total_flops/10)\n",
    "print(\"Avg runtime in seconds:\", total_time/10)\n",
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdafdcef-1475-46c2-902a-ab6159ed115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan</th>\n",
       "      <th>cat</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>java</td>\n",
       "      <td>summary</td>\n",
       "      <td>0.871224</td>\n",
       "      <td>0.886731</td>\n",
       "      <td>0.878909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>java</td>\n",
       "      <td>Ownership</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "      <td>Expand</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>0.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>java</td>\n",
       "      <td>usage</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>0.850847</td>\n",
       "      <td>0.867012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>java</td>\n",
       "      <td>Pointer</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.861210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>java</td>\n",
       "      <td>deprecation</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>java</td>\n",
       "      <td>rational</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>python</td>\n",
       "      <td>Usage</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.673913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>python</td>\n",
       "      <td>Parameters</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>python</td>\n",
       "      <td>DevelopmentNotes</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>python</td>\n",
       "      <td>Expand</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>python</td>\n",
       "      <td>Summary</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.672269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Keyimplementationpoints</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Example</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Responsibilities</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.681319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Intent</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Keymessages</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Collaborators</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lan                      cat  precision    recall        f1\n",
       "0     java                  summary   0.871224  0.886731  0.878909\n",
       "1     java                Ownership   1.000000  1.000000  1.000000\n",
       "2     java                   Expand   0.330097  0.430380  0.373626\n",
       "3     java                    usage   0.883803  0.850847  0.867012\n",
       "4     java                  Pointer   0.775641  0.968000  0.861210\n",
       "5     java              deprecation   0.875000  0.700000  0.777778\n",
       "6     java                 rational   0.311688  0.413793  0.355556\n",
       "7   python                    Usage   0.666667  0.681319  0.673913\n",
       "8   python               Parameters   0.688172  0.752941  0.719101\n",
       "9   python         DevelopmentNotes   0.219178  0.500000  0.304762\n",
       "10  python                   Expand   0.453333  0.666667  0.539683\n",
       "11  python                  Summary   0.689655  0.655738  0.672269\n",
       "12   pharo  Keyimplementationpoints   0.562500  0.642857  0.600000\n",
       "13   pharo                  Example   0.886364  0.876404  0.881356\n",
       "14   pharo         Responsibilities   0.632653  0.738095  0.681319\n",
       "15   pharo                   Intent   0.720000  0.857143  0.782609\n",
       "16   pharo              Keymessages   0.478261  0.733333  0.578947\n",
       "17   pharo            Collaborators   0.103448  0.428571  0.166667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "110888a6-68b1-47e8-9cf1-dfc69b8ec683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    java_train: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 5394\n",
       "    })\n",
       "    java_test: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 1201\n",
       "    })\n",
       "    pharo_train: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    pharo_test: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 208\n",
       "    })\n",
       "    python_train: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 1368\n",
       "    })\n",
       "    python_test: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d796cbf-552e-4712-9cbf-768dd40b5c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.76)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_avg_runtime = 5\n",
    "max_avg_flops = 5000\n",
    "# s𝑢𝑏𝑚𝑖𝑠𝑠𝑖𝑜𝑛_𝑠𝑐𝑜𝑟𝑒(𝑚𝑜𝑑𝑒𝑙)=(𝑎𝑣𝑔. 𝐹1)×0.60+max((𝑚𝑎𝑥_𝑎𝑣𝑔_𝑟𝑢𝑛𝑡𝑖𝑚𝑒−𝑚𝑒𝑎𝑠𝑢𝑟𝑒𝑑_𝑎𝑣𝑔_𝑟𝑢𝑛𝑡𝑖𝑚𝑒)/𝑚𝑎𝑥_𝑎𝑣𝑔_𝑟𝑢𝑛𝑡𝑖𝑚𝑒),0)×0.2+max(((𝑚𝑎𝑥_GFLOPs−𝑚𝑒𝑎𝑠𝑢𝑟𝑒𝑑_GFLOPs)/𝑚𝑎𝑥_GFLOPs), 0)×0.2\n",
    "def score(avg_f1, avg_runtime, avg_flops):\n",
    "    return (0.6 * avg_f1 +\n",
    "      0.2 * max((max_avg_runtime - avg_runtime) / max_avg_runtime, 0) +\n",
    "      0.2 * max((max_avg_flops - avg_flops) / max_avg_flops), 0)\n",
    "\n",
    "avg_f1 = scores.f1.mean()\n",
    "avg_runtime = total_time/10\n",
    "avg_flops = total_flops/10\n",
    "\n",
    "round(score(avg_f1, avg_runtime, avg_flops), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
