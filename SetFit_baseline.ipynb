{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c546aa23-dc4f-4882-911d-b751a64fe5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pip install setfit==1.1.2 datasets=3.6.0\n",
    "# expects that the folder models exists\n",
    "import pandas as pd\n",
    "import time\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba5ab32-a3d9-468a-a70c-7010123f2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['java', 'python', 'pharo']\n",
    "labels = {\n",
    "    'java': ['summary', 'Ownership', 'Expand', 'usage', 'Pointer', 'deprecation', 'rational'],\n",
    "    'python': ['Usage', 'Parameters', 'DevelopmentNotes', 'Expand', 'Summary'],\n",
    "    'pharo': ['Keyimplementationpoints', 'Example', 'Responsibilities', 'Intent', 'Keymessages', 'Collaborators']\n",
    "}\n",
    "ds = load_dataset('NLBSE/nlbse26-code-comment-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39abcb0-235a-4e6d-9f89-d585711c7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs:\n",
    "    model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\", multi_target_strategy=\"multi-output\")\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        num_epochs=5 if lang == 'java' else 10,\n",
    "        batch_size=32,\n",
    "        num_iterations=20\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=ds[f'{lang}_train'],\n",
    "        eval_dataset=ds[f'{lang}_test'],\n",
    "        column_mapping={\"combo\": \"text\", \"labels\": \"label\"}\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.model.save_pretrained(f'./models/{lang}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5049af86-918a-4f50-8a2c-4ad922f3f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/moritzmock/PycharmProjects/NLBSE'26/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute in GFLOPs: 0.355315968\n",
      "Avg runtime in seconds: 0.9584410905838012\n"
     ]
    }
   ],
   "source": [
    "total_flops = 0\n",
    "total_time = 0\n",
    "scores = []\n",
    "for lan in langs:\n",
    "    # to load trained models:\n",
    "    # model = SetFitModel.from_pretrained(f'./models/{lan}')\n",
    "    # to load pretrained models from Hub:\n",
    "    model = SetFitModel.from_pretrained(f'NLBSE/nlbse26_{lan}')\n",
    "    with torch.profiler.profile(with_flops=True) as p:\n",
    "        x = ds[f'{lan}_test'][:][\"combo\"]\n",
    "        begin = time.time()\n",
    "        for i in range(10):\n",
    "          y_pred = model(x)\n",
    "          y_pred = np.asarray(y_pred).T \n",
    "        total = time.time() - begin\n",
    "        total_time = total_time + total\n",
    "    total_flops = total_flops + (sum(k.flops for k in p.key_averages()) / 1e9)\n",
    "    y_true = np.array(ds[f'{lan}_test']['labels']).T\n",
    "    for i in range(len(y_pred)):\n",
    "        assert(len(y_pred[i]) == len(y_true[i]))\n",
    "        tp = sum([true == pred == 1 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        tn = sum([true == pred == 0 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        fp = sum([true == 0 and pred == 1 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        fn = sum([true == 1 and pred == 0 for (true,pred) in zip(y_true[i], y_pred[i])])\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2*tp) / (2*tp + fp + fn)\n",
    "        scores.append({'lan': lan, 'cat': labels[lan][i],'precision': precision,'recall': recall,'f1': f1})\n",
    "print(\"Compute in GFLOPs:\", total_flops/10)\n",
    "print(\"Avg runtime in seconds:\", total_time/10)\n",
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdafdcef-1475-46c2-902a-ab6159ed115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan</th>\n",
       "      <th>cat</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>java</td>\n",
       "      <td>summary</td>\n",
       "      <td>0.871224</td>\n",
       "      <td>0.886731</td>\n",
       "      <td>0.878909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>java</td>\n",
       "      <td>Ownership</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "      <td>Expand</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>0.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>java</td>\n",
       "      <td>usage</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>0.850847</td>\n",
       "      <td>0.867012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>java</td>\n",
       "      <td>Pointer</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.861210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>java</td>\n",
       "      <td>deprecation</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>java</td>\n",
       "      <td>rational</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>python</td>\n",
       "      <td>Usage</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.673913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>python</td>\n",
       "      <td>Parameters</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>python</td>\n",
       "      <td>DevelopmentNotes</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>python</td>\n",
       "      <td>Expand</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>python</td>\n",
       "      <td>Summary</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.672269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Keyimplementationpoints</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Example</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Responsibilities</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.681319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Intent</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Keymessages</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pharo</td>\n",
       "      <td>Collaborators</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lan                      cat  precision    recall        f1\n",
       "0     java                  summary   0.871224  0.886731  0.878909\n",
       "1     java                Ownership   1.000000  1.000000  1.000000\n",
       "2     java                   Expand   0.330097  0.430380  0.373626\n",
       "3     java                    usage   0.883803  0.850847  0.867012\n",
       "4     java                  Pointer   0.775641  0.968000  0.861210\n",
       "5     java              deprecation   0.875000  0.700000  0.777778\n",
       "6     java                 rational   0.311688  0.413793  0.355556\n",
       "7   python                    Usage   0.666667  0.681319  0.673913\n",
       "8   python               Parameters   0.688172  0.752941  0.719101\n",
       "9   python         DevelopmentNotes   0.219178  0.500000  0.304762\n",
       "10  python                   Expand   0.453333  0.666667  0.539683\n",
       "11  python                  Summary   0.689655  0.655738  0.672269\n",
       "12   pharo  Keyimplementationpoints   0.562500  0.642857  0.600000\n",
       "13   pharo                  Example   0.886364  0.876404  0.881356\n",
       "14   pharo         Responsibilities   0.632653  0.738095  0.681319\n",
       "15   pharo                   Intent   0.720000  0.857143  0.782609\n",
       "16   pharo              Keymessages   0.478261  0.733333  0.578947\n",
       "17   pharo            Collaborators   0.103448  0.428571  0.166667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "110888a6-68b1-47e8-9cf1-dfc69b8ec683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    java_train: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 5394\n",
       "    })\n",
       "    java_test: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 1201\n",
       "    })\n",
       "    pharo_train: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    pharo_test: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 208\n",
       "    })\n",
       "    python_train: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 1368\n",
       "    })\n",
       "    python_test: Dataset({\n",
       "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
       "        num_rows: 290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d796cbf-552e-4712-9cbf-768dd40b5c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.76)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_avg_runtime = 5\n",
    "max_avg_flops = 5000\n",
    "# sğ‘¢ğ‘ğ‘šğ‘–ğ‘ ğ‘ ğ‘–ğ‘œğ‘›_ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘šğ‘œğ‘‘ğ‘’ğ‘™)=(ğ‘ğ‘£ğ‘”. ğ¹1)Ã—0.60+max((ğ‘šğ‘ğ‘¥_ğ‘ğ‘£ğ‘”_ğ‘Ÿğ‘¢ğ‘›ğ‘¡ğ‘–ğ‘šğ‘’âˆ’ğ‘šğ‘’ğ‘ğ‘ ğ‘¢ğ‘Ÿğ‘’ğ‘‘_ğ‘ğ‘£ğ‘”_ğ‘Ÿğ‘¢ğ‘›ğ‘¡ğ‘–ğ‘šğ‘’)/ğ‘šğ‘ğ‘¥_ğ‘ğ‘£ğ‘”_ğ‘Ÿğ‘¢ğ‘›ğ‘¡ğ‘–ğ‘šğ‘’),0)Ã—0.2+max(((ğ‘šğ‘ğ‘¥_GFLOPsâˆ’ğ‘šğ‘’ğ‘ğ‘ ğ‘¢ğ‘Ÿğ‘’ğ‘‘_GFLOPs)/ğ‘šğ‘ğ‘¥_GFLOPs), 0)Ã—0.2\n",
    "def score(avg_f1, avg_runtime, avg_flops):\n",
    "    return (0.6 * avg_f1 +\n",
    "      0.2 * max((max_avg_runtime - avg_runtime) / max_avg_runtime, 0) +\n",
    "      0.2 * max((max_avg_flops - avg_flops) / max_avg_flops), 0)\n",
    "\n",
    "avg_f1 = scores.f1.mean()\n",
    "avg_runtime = total_time/10\n",
    "avg_flops = total_flops/10\n",
    "\n",
    "round(score(avg_f1, avg_runtime, avg_flops), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
